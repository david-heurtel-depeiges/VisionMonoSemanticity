{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/pvz51gzx2lyqpabf08xhd1y2kvw5rfdy-python-3.9.16-view/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/mnt/sw/nix/store/d9jbiy4kghz72ak7mija92asihk8xcja-py-torchvision-0.15.2/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.corpus import wordnet as wn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import pytorch_lightning as pl\n",
    "import wandb\n",
    "import re\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import AutoEncoder, HookedModel, DictionnaryLearner, default_hookedmodel, default_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(generic_path, wandb_id, epoch = -1):\n",
    "    path = os.path.join(generic_path, wandb_id, 'checkpoints')\n",
    "    if epoch == -1:\n",
    "        ## Create a list of all the epochs with a regex\n",
    "        epochs = [int(re.findall(r'epoch=(\\d+)', x)[0]) for x in os.listdir(path)]\n",
    "        ## Get the last epoch\n",
    "        epoch = max(epochs)\n",
    "    ## Get the ckpt file starting with epoch={epoch}\n",
    "    ckpt = [x for x in os.listdir(path) if x.startswith(f'epoch={epoch}')][0]\n",
    "    model = DictionnaryLearner.load_from_checkpoint(os.path.join(path, ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavid-heurtel-depeiges\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config\n",
    "\n",
    "## Data\n",
    "TRAIN_PATH = '/tmp/imagenet/train'\n",
    "VAL_PATH = '/tmp/imagenet/valid'\n",
    "\n",
    "## Data transforms\n",
    "PATCH_SIZE = 'Full'\n",
    "\n",
    "## Model \n",
    "D_HIDDEN = 1024\n",
    "CHANNELS = 508\n",
    "D_MULT = 1 ## If not 1, D_HIDDEN = CHANNELS * D_MULT\n",
    "if D_MULT != 1:\n",
    "    D_HIDDEN = CHANNELS * D_MULT\n",
    "L1_COEFF = 3e-4\n",
    "\n",
    "\n",
    "MODEL_NAME = 'inceptionv1_mixed4a_monosemantic'\n",
    "\n",
    "## Training\n",
    "BATCH_SIZE = 4096\n",
    "OPTIM = 'Adam'\n",
    "\n",
    "\n",
    "## Checkpointing\n",
    "SAVE_PATH = '/path/to/checkpoints/monosemantic/'\n",
    "\n",
    "## Logging\n",
    "\n",
    "WANBD_PROJECT = 'monosemantic_dictionnary_learning'\n",
    "\n",
    "os.makedirs(SAVE_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'dataset': 'imagenet',\n",
    "    'patch_size': PATCH_SIZE,\n",
    "    'd_input' : CHANNELS,\n",
    "    'd_hidden': D_HIDDEN,\n",
    "    'l1_coeff': L1_COEFF,\n",
    "    'model_name': MODEL_NAME,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'optim': OPTIM,\n",
    "    'save_path': SAVE_PATH,\n",
    "    'wandb_project': WANBD_PROJECT, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirnotempy = os.path.exists('/tmp/imagenet/train')\n",
    "if dirnotempy:\n",
    "    l = os.listdir('/tmp/imagenet/train')\n",
    "    if len(l)==0:\n",
    "        dirnotempy = False\n",
    "if not dirnotempy:\n",
    "    os.system('bash dataload.sh')\n",
    "\n",
    "traindir = os.path.join('/tmp/imagenet/', 'train')\n",
    "valdir = os.path.join('/tmp/imagenet/', 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "def unormalize(batch):\n",
    "    ## batch of shape (batch_size, 3, 224, 224)\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)\n",
    "\n",
    "    return batch * std + mean\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    valdir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/path/to/checkpoints/monosemantic/inceptionv1_mixed4a_monosemantic/monosemantic_dictionnary_learning/', 'w6oqqydk', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/dheurtel/venv/genv_DL/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:198: Attribute 'layer_to_hook' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['layer_to_hook'])`.\n"
     ]
    }
   ],
   "source": [
    "dict_learner = DictionnaryLearner(d_hidden = 10 * 508, d_input = 508, l1_coeff = 1e-2, layer_to_hook='mixed5b', patch_size = None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/home/dheurtel/VisionMonoSemanticity/dictionnary_learning.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bworkergpu089/mnt/home/dheurtel/VisionMonoSemanticity/dictionnary_learning.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(train_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bworkergpu089/mnt/home/dheurtel/VisionMonoSemanticity/dictionnary_learning.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m val_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(val_dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=8)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger_type = 'tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/pvz51gzx2lyqpabf08xhd1y2kvw5rfdy-python-3.9.16-view/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/callback_connector.py:90: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=20)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type        | Params\n",
      "--------------------------------------------\n",
      "0 | autoencoder | AutoEncoder | 5.2 M \n",
      "1 | hookedmodel | HookedModel | 7.1 M \n",
      "--------------------------------------------\n",
      "5.2 M     Trainable params\n",
      "7.1 M     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.933    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786961587dea4d59bd3914d797274282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sw/nix/store/pvz51gzx2lyqpabf08xhd1y2kvw5rfdy-python-3.9.16-view/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:453: UserWarning: Your `val_dataloader` has `shuffle=True`,it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n",
      "/mnt/sw/nix/store/pvz51gzx2lyqpabf08xhd1y2kvw5rfdy-python-3.9.16-view/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:407: UserWarning: The number of training samples (8) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c036ae1b88943ab8ea0aca1d0146b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a26a4f49624a6f94febf3b3e7f3703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if logger_type.lower()=='wandb':\n",
    "    logger = pl.loggers.WandbLogger(project=WANBD_PROJECT, config=CONFIG)\n",
    "    logger.watch(dict_learner)\n",
    "    logger.log_hyperparams(CONFIG)\n",
    "    default_root_dir = None\n",
    "elif logger_type.lower()=='tensorboard':\n",
    "    logger = pl.loggers.TensorBoardLogger(SAVE_PATH, name=MODEL_NAME)\n",
    "    default_root_dir = None\n",
    "else:\n",
    "    logger = None\n",
    "    default_root_dir = SAVE_PATH\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(SAVE_PATH, name=MODEL_NAME)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=1, progress_bar_refresh_rate=20,default_root_dir=default_root_dir, logger=logger)\n",
    "trainer.fit(dict_learner, train_dataloaders=dummy_dataloader, val_dataloaders=dummy_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
